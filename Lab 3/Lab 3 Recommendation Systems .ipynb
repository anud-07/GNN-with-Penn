{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cd757a7",
   "metadata": {},
   "source": [
    "The below function load_data takes in the index of the movie whose ratings we want to predict and the minimum number of ratings per column, and returns the cleaned-up rating matrix and the new index of movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1576157f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 203) 109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import zipfile # To handle zip files\n",
    "import torch as torch\n",
    "\n",
    "def load_data(movie, min_ratings):\n",
    "    \n",
    "    # Extract all from zip file\n",
    "    dataDir=os.getcwd()\n",
    "    zipObject = zipfile.ZipFile(os.path.join(dataDir,'ml-100k.zip'))\n",
    "    zipObject.extractall(dataDir)\n",
    "    zipObject.close()\n",
    "    \n",
    "    rawDataFilename = os.path.join(dataDir,'ml-100k','u.data')\n",
    "    \n",
    "    # Initialize rating matrix\n",
    "    rawMatrix = np.empty([0, 0]) \n",
    "    \n",
    "    # From each row of u.data, extract userID, movieID and rating\n",
    "    with open(rawDataFilename, 'r') as rawData:\n",
    "        for dataLine in rawData:\n",
    "            dataLineSplit = dataLine.rstrip('\\n').split('\\t')\n",
    "            userID = int(dataLineSplit[0])\n",
    "            movieID = int(dataLineSplit[1])\n",
    "            rating = int(dataLineSplit[2])\n",
    "            if userID > rawMatrix.shape[0]:\n",
    "                rowDiff = userID - rawMatrix.shape[0]\n",
    "                zeroPadRows = np.zeros([rowDiff, rawMatrix.shape[1]])\n",
    "                rawMatrix = np.concatenate((rawMatrix, zeroPadRows),\n",
    "                                           axis = 0)\n",
    "            if movieID > rawMatrix.shape[1]:\n",
    "                colDiff = movieID - rawMatrix.shape[1]\n",
    "                zeroPadCols = np.zeros([rawMatrix.shape[0], colDiff])\n",
    "                rawMatrix = np.concatenate((rawMatrix, zeroPadCols),\n",
    "                                           axis = 1)\n",
    "                \n",
    "            # Assign rating to rating matrix\n",
    "            rawMatrix[userID - 1, movieID - 1] = rating\n",
    "          \n",
    "    # Define X\n",
    "    X = rawMatrix\n",
    "    \n",
    "    # Count number of ratings per column, i.e., per movie\n",
    "    nbRatingsCols = np.sum(X>0,axis=0)\n",
    "    \n",
    "    # Mask to identify movies with at least min_ratings\n",
    "    mask = nbRatingsCols >= min_ratings\n",
    "    \n",
    "    # Save new index of the input argument \"movie\"\n",
    "    idxMovie = np.sum(mask[0:movie])\n",
    "    \n",
    "    \n",
    "    # 1.2 Data clean-up:\n",
    "    \n",
    "    # Remove matrix columns\n",
    "    idx = np.argwhere(mask>0).squeeze()\n",
    "    X = X[:,idx.squeeze()]\n",
    "    \n",
    "    # Make sure there are no rows of all zeros\n",
    "    nbRatingsRows = np.sum(X>0,axis=1)\n",
    "    idx = np.argwhere(nbRatingsRows>0).squeeze()\n",
    "    X=X[idx,:]\n",
    "    \n",
    "    # Return cleaned-up X and new index of input argument \"movie\"\n",
    "    return X, idxMovie\n",
    "\n",
    "X, idxContact = load_data(movie=257, min_ratings=150)\n",
    "print(X.shape, idxContact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7795c6",
   "metadata": {},
   "source": [
    "The input arguments of the function \"def create_graph\" are:\n",
    "X, the rating matrix; \n",
    "IndexTrain, the indices of the users in the training set; \n",
    "knn, the number of neighbors to keep when sparsifying the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e63d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(X, idxTrain, knn):\n",
    "    \n",
    "    # Everything below 1e-9 is considered zero\n",
    "    zeroTolerance = 1e-9\n",
    "    \n",
    "    # Number of nodes is equal to the number of columns (movies)\n",
    "    N = X.shape[1]\n",
    "    \n",
    "    # Isolating users used for training\n",
    "    XTrain = np.transpose(X[idxTrain,:])\n",
    "    \n",
    "    # Calculating correlation matrix\n",
    "    binaryTemplate = (XTrain > 0).astype(XTrain.dtype)\n",
    "    sumMatrix = XTrain.dot(binaryTemplate.T)\n",
    "    countMatrix = binaryTemplate.dot(binaryTemplate.T)\n",
    "    countMatrix[countMatrix == 0] = 1\n",
    "    avgMatrix = sumMatrix / countMatrix\n",
    "    sqSumMatrix = (XTrain ** 2).dot(binaryTemplate.T)\n",
    "    correlationMatrix = sqSumMatrix / countMatrix - avgMatrix ** 2\n",
    "    \n",
    "    # Normalizing by diagonal weights\n",
    "    sqrtDiagonal = np.sqrt(np.diag(correlationMatrix))\n",
    "    nonzeroSqrtDiagonalIndex = (sqrtDiagonal > zeroTolerance)\\\n",
    "                                                 .astype(sqrtDiagonal.dtype)\n",
    "    sqrtDiagonal[sqrtDiagonal < zeroTolerance] = 1.\n",
    "    invSqrtDiagonal = 1/sqrtDiagonal\n",
    "    invSqrtDiagonal = invSqrtDiagonal * nonzeroSqrtDiagonalIndex\n",
    "    normalizationMatrix = np.diag(invSqrtDiagonal)\n",
    "    \n",
    "    # Zero-ing the diagonal\n",
    "    normalizedMatrix = normalizationMatrix.dot(\n",
    "                            correlationMatrix.dot(normalizationMatrix)) \\\n",
    "                            - np.eye(correlationMatrix.shape[0])\n",
    "\n",
    "    # Keeping only edges with weights above the zero tolerance\n",
    "    normalizedMatrix[np.abs(normalizedMatrix) < zeroTolerance] = 0.\n",
    "    W = normalizedMatrix\n",
    "    \n",
    "    # Sparsifying the graph\n",
    "    WSorted = np.sort(W,axis=1)\n",
    "    threshold = WSorted[:,-knn].squeeze()\n",
    "    thresholdMatrix = (np.tile(threshold,(N,1))).transpose()\n",
    "    W[W<thresholdMatrix] = 0\n",
    "    \n",
    "    # Normalizing by eigenvalue with largest magnitude\n",
    "    E, V = np.linalg.eig(W)\n",
    "    W = W/np.max(np.abs(E))\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab95280",
   "metadata": {},
   "source": [
    "Use the following function to generate the graph using a training set with 90% of the users selected at random and 40% nearest neighbors per nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a075fe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203, 203)\n"
     ]
    }
   ],
   "source": [
    "# Creating and sparsifying the graph\n",
    "\n",
    "nTotal = X.shape[0] # total number of users (samples)\n",
    "permutation = np.random.permutation(nTotal)\n",
    "nTrain = int(np.ceil(0.9*nTotal)) # number of training samples\n",
    "idxTrain = permutation[0:nTrain] # indices of training samples\n",
    "nTest = nTotal-nTrain # number of test samples\n",
    "idxTest=permutation[nTrain:nTotal] # indices of test samples\n",
    "\n",
    "W = create_graph(X=X, idxTrain=idxTrain, knn=40)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c5d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 41\n"
     ]
    }
   ],
   "source": [
    "def split_data(X, idxTrain, idxTest, idxMovie):  \n",
    "    \n",
    "    N = X.shape[1]\n",
    "    \n",
    "    xTrain = X[idxTrain,:]\n",
    "    idx = np.argwhere(xTrain[:,idxMovie]>0).squeeze()\n",
    "    xTrain = xTrain[idx,:]\n",
    "    yTrain = np.zeros(xTrain.shape)\n",
    "    yTrain[:,idxMovie] = xTrain[:,idxMovie]\n",
    "    xTrain[:,idxMovie] = 0\n",
    "    \n",
    "    xTrain = torch.tensor(xTrain)\n",
    "    xTrain = xTrain.reshape([-1,1,N])\n",
    "    yTrain = torch.tensor(yTrain)\n",
    "    yTrain = yTrain.reshape([-1,1,N])\n",
    "    \n",
    "    xTest = X[idxTest,:]\n",
    "    idx = np.argwhere(xTest[:,idxMovie]>0).squeeze()\n",
    "    xTest = xTest[idx,:]\n",
    "    yTest = np.zeros(xTest.shape)\n",
    "    yTest[:,idxMovie] = xTest[:,idxMovie]\n",
    "    xTest[:,idxMovie] = 0\n",
    "    \n",
    "    xTest = torch.tensor(xTest)\n",
    "    xTest = xTest.reshape([-1,1,N])\n",
    "    yTest = torch.tensor(yTest)\n",
    "    yTest = yTest.reshape([-1,1,N])\n",
    "    \n",
    "    return xTrain, yTrain, xTest, yTest\n",
    "\n",
    "\n",
    "xTrain, yTrain, xTest, yTest =split_data(X, idxTrain, idxTest, idxContact)\n",
    "nTrain = xTrain.shape[0]\n",
    "nTest = xTest.shape[0]\n",
    "\n",
    "print(nTrain, nTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab2ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
